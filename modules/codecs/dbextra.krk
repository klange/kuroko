"""
This module includes some additional variable-width or wide encodings not specified by WHATWG. As 
such, none of the codecs in this module should be used in HTML.
"""

from codecs.extradata import encode_lat1supp, decode_lat1supp, encode_greksupp, decode_greksupp, encode_jis78, decode_jis78, encode_jis90p2, decode_jis90p2, encode_jis00, decode_jis00, encode_jis00p2, decode_jis00p2, encode_jis04, decode_jis04, encode_jis7katakana, encode_gb7, decode_gb7, encode_ksc7, decode_ksc7, encode_nbyte_ebcdic, decode_nbyte_ebcdic, encode_johab_ascii, decode_johab_ascii, encode_johab_ebcdic, decode_johab_ebcdic, encode_euc90, encode_euc04, decode_euc04, encode_sjis04, decode_sjis04, encode_big5_nonetenkana, decode_big5_nonetenkana
from codecs.infrastructure import register_kuroko_codec, ByteCatenator, StringCatenator, UnicodeEncodeError, UnicodeDecodeError, lookup_error, lookup, BaseEbcdicIncrementalEncoder, BaseEbcdicIncrementalDecoder, AsciiIncrementalEncoder, AsciiIncrementalDecoder, IncrementalEncoder, IncrementalDecoder, encode_base64, decode_base64
from codecs.dbdata import encode_jis7, decode_jis7, decode_jis7katakana, XEucJpIncrementalDecoder, Big5EtenIncrementalEncoder, Big5HkscsIncrementalDecoder, encode_gbk, decode_gbk
from codecs.bespokecodecs import Iso2022JpIncrementalEncoder, Iso2022JpIncrementalDecoder, Utf8IncrementalDecoder, Utf16BeIncrementalEncoder, Utf16BeIncrementalDecoder
from collections import xraydict

let cp950_no_eudc_encoding_map = xraydict(Big5EtenIncrementalEncoder.encoding_map, {
        0x2550: (0xA2, 0xA4),
        0x255E: (0xA2, 0xA5),
        0x256A: (0xA2, 0xA6),
        0x2561: (0xA2, 0xA7),
    },
    [i for i in Big5EtenIncrementalEncoder.encoding_map.keys()
        if Big5EtenIncrementalEncoder.encoding_map[i][0] in (0xC7, 0xC8) or (
            Big5EtenIncrementalEncoder.encoding_map[i][0] == 0xC6 and
            Big5EtenIncrementalEncoder.encoding_map[i][1] >= 0xA1
        )
    ]
)

let cp950_no_eudc_decoding_map = xraydict(Big5HkscsIncrementalDecoder.decoding_map, {},
    [i for i in Big5HkscsIncrementalDecoder.decoding_map.keys()
        if i[0] < 0xA1 or i[0] > 0xF9 or i[0] in (0xC7, 0xC8) or (i[0] == 0xC6 and i[1] >= 0xA1)])

class Big5NonEtenKanaIncrementalEncoder(AsciiIncrementalEncoder):
    name = "big5-nonetenkana"
    html5name = None
    encoding_map = xraydict(cp950_no_eudc_encoding_map, encode_big5_nonetenkana)

class Big5NonEtenKanaIncrementalDecoder(AsciiIncrementalDecoder):
    name = "big5-nonetenkana"
    html5name = None
    decoding_map = xraydict(cp950_no_eudc_decoding_map, decode_big5_nonetenkana)
    dbrange = Big5HkscsIncrementalDecoder.dbrange
    trailrange = Big5HkscsIncrementalDecoder.trailrange

register_kuroko_codec(["big5-nonetenkana", "big5-tw"],
    Big5NonEtenKanaIncrementalEncoder, Big5NonEtenKanaIncrementalDecoder)

class XMacChineseTradIncrementalEncoder(AsciiIncrementalEncoder):
    name = "x-mac-chinesetrad"
    html5name = None
    encoding_map = xraydict(cp950_no_eudc_encoding_map, {
        0xB7: (0xA1, 0x45),
        0x22EF: (0xA1, 0x4B),
        0x203E: (0xA1, 0xC2),
        0x223C: (0xA1, 0xE3),
        0x2609: (0xA1, 0xF3),
        0xA5: (0xA2, 0x44),
        0xA2: (0xA2, 0x46),
        0xA3: (0xA2, 0x47),
        0xF880: 0x81,
        0xF881: 0x82,
        0xA0: 0xA0,
        0xA9: 0xFD,
        0x2122: 0xFE,
        0x2026: 0xFF,
    })

class XMacChineseTradIncrementalDecoder(AsciiIncrementalDecoder):
    name = "x-mac-chinesetrad"
    html5name = None
    decoding_map = xraydict(cp950_no_eudc_decoding_map, {
        (0xA1, 0x45): 0xB7,
        (0xA1, 0x4B): 0x22EF,
        (0xA1, 0xC2): 0x203E,
        (0xA1, 0xE3): 0x223C,
        (0xA1, 0xF3): 0x2609,
        (0xA2, 0x44): 0xA5,
        (0xA2, 0x46): 0xA2,
        (0xA2, 0x47): 0xA3,
        0x80: 0x5C,
        0x81: 0xF880,
        0x82: 0xF881,
        0xA0: 0xA0,
        0xFD: 0xA9,
        0xFE: 0x2122,
        0xFF: 0x2026,
    })
    dbrange = tupleOf(*range(0xA1, 0xFC + 1))
    trailrange = Big5HkscsIncrementalDecoder.trailrange

register_kuroko_codec(["x-mac-chinesetrad", "x-mac-trad-chinese"],
    XMacChineseTradIncrementalEncoder, XMacChineseTradIncrementalDecoder)


let encode_gb8 = xraydict(encode_gbk, {
        0xFE10: (0xA6, 0xD9),
        0xFE12: (0xA6, 0xDA),
        0xFE11: (0xA6, 0xDB),
        0xFE13: (0xA6, 0xDC),
        0xFE14: (0xA6, 0xDD),
        0xFE15: (0xA6, 0xDE),
        0xFE16: (0xA6, 0xDF),
        0xFE17: (0xA6, 0xEC),
        0xFE18: (0xA6, 0xED),
        0xFE19: (0xA6, 0xF3),
    }, [i for i in encode_gbk.keys() if 
        len(encode_gbk[i]) != 2 or
        (not (0xA1 <= encode_gbk[i][0] and encode_gbk[i][0] <= 0xFC)) or
        encode_gbk[i][1] < 0xA1])

let decode_gb8 = xraydict(decode_gbk, {
        (0xA6, 0xD9): 0xFE10,
        (0xA6, 0xDA): 0xFE12,
        (0xA6, 0xDB): 0xFE11,
        (0xA6, 0xDC): 0xFE13,
        (0xA6, 0xDD): 0xFE14,
        (0xA6, 0xDE): 0xFE15,
        (0xA6, 0xDF): 0xFE16,
        (0xA6, 0xEC): 0xFE17,
        (0xA6, 0xED): 0xFE18,
        (0xA6, 0xF3): 0xFE19,
    })

class XMacChineseSimpIncrementalEncoder(AsciiIncrementalEncoder):
    name = "x-mac-chinesesimp"
    html5name = None
    encoding_map = xraydict(encode_gb8, {
        0x301C: (0xA1, 0xAB),
        0x22EF: (0xA1, 0xAD),
        0xA2: (0xA1, 0xE9),
        0xA3: (0xA1, 0xEA),
        0x203E: (0xA3, 0xFE),
        0xF880: 0x81,
        0xF881: 0x82,
        0xA0: 0xA0,
        0xA9: 0xFD,
        0x2122: 0xFE,
        0x2026: 0xFF,
    })

class XMacChineseSimpIncrementalDecoder(AsciiIncrementalDecoder):
    name = "x-mac-chinesesimp"
    html5name = None
    decoding_map = xraydict(decode_gb8, {
        (0xA1, 0xAB): 0x301C,
        (0xA1, 0xAD): 0x22EF,
        (0xA1, 0xE9): 0xA2,
        (0xA1, 0xEA): 0xA3,
        (0xA3, 0xFE): 0x203E,
        0x80: 0xFC,
        0x81: 0xF880,
        0x82: 0xF881,
        0xA0: 0xA0,
        0xFD: 0xA9,
        0xFE: 0x2122,
        0xFF: 0x2026,
    })
    dbrange = tupleOf(*range(0xA1, 0xFC + 1))
    trailrange = tupleOf(*range(0xA1, 0xFE + 1))

register_kuroko_codec(["x-mac-chinesesimp", "x-mac-simp-chinese", "euc-cn", "euccn", "eucgb2312-cn"],
    XMacChineseSimpIncrementalEncoder, XMacChineseSimpIncrementalDecoder)


class Cesu8IncrementalEncoder(IncrementalEncoder):
    name = "cesu-8"
    html5name = None
    # -1: expecting BOM
    #  0: Normal
    state = None
    include_bom = False
    def encode(string, final = False):
        let out = ByteCatenator()
        if self.include_bom and self.state == -1:
            out.add("\uFEFF".encode())
        self.state = 0
        let first_offset = 0
        let second_offset = 0
        while second_offset < len(string):
            let codepoint = ord(string[second_offset])
            if 0x10000 <= codepoint and codepoint <= 0x10FFFF:
                out.add(string[first_offset:second_offset].encode())
                let bits_remaining = codepoint - 0x10000
                let sixth = 0x80 | (bits_remaining & 0x3F)
                bits_remaining >>= 6
                let fifth = 0xB0 | (bits_remaining & 0xF)
                bits_remaining >>= 4
                let third = 0x80 | (bits_remaining & 0x3F)
                bits_remaining >>= 6
                let second = 0xA0 | bits_remaining
                out.add(bytes([0xED, second, third, 0xED, fifth, sixth]))
                second_offset += 1
                first_offset = second_offset
            else:
                second_offset += 1
        out.add(string[first_offset:second_offset].encode())
        return out.getvalue()
    def reset():
        self.state = -1
    def getstate():
        return self.state
    def setstate(state):
        self.state = state

class Cesu8IncrementalDecoder(Utf8IncrementalDecoder):
    name = "cesu-8"
    html5name = None
    def _error_handler(error):
        # Note: not error.end (which is set after noticing the CESU seq, not at the end of it).
        let after_cesu = error.start + 6
        let maybe_cesu = list(error.object)[error.start:after_cesu]
        if len(maybe_cesu) == 6 and (
                    maybe_cesu[0] == 0xED and 0xA0 <= maybe_cesu[1] and maybe_cesu[1] <= 0xAF
                ) and (
                    maybe_cesu[3] == 0xED and 0xB0 <= maybe_cesu[4] and maybe_cesu[4] <= 0xBF):
            let codepoint = 0
            codepoint |= maybe_cesu[1] & 0xF
            codepoint <<= 6
            codepoint |= maybe_cesu[2] & 0x3F
            codepoint <<= 4
            codepoint |= maybe_cesu[4] & 0xF
            codepoint <<= 6
            codepoint |= maybe_cesu[5] & 0x3F
            codepoint += 0x10000
            return (chr(codepoint), after_cesu)
        elif len(maybe_cesu) >= 2 and maybe_cesu[0] == 0xC0 and maybe_cesu[1] == 0x80:
            # mUTF-8 is a fairly common CESU-8 variant, using the two-byte code for embedded NUL
            return ("\x00", error.start + 2)
        else:
            return lookup_error(self.errors)(error)

register_kuroko_codec(["utf8-ucs2", "utf8mb3", "cesu-8", "cesu8"],
    Cesu8IncrementalEncoder, Cesu8IncrementalDecoder)


let _verbatim_utf7 = (
    list(range(ord("A"), ord("Z") + 1)) + 
    list(range(ord("a"), ord("z") + 1)) +
    list(range(ord("0"), ord("9") + 1)) + [ord(i) for i in "/-(),.:? \r\n"]
)
let _utf7_not_need_hyphen = [ord(i) for i in "(),.:? \r\n"]
class Utf7IncrementalEncoder(IncrementalEncoder):
    name = "utf-7"
    html5name = None
    utf16encoder = None
    mode = "ascii"
    pending = []
    def __init__(errors):
        self.utf16encoder = Utf16BeIncrementalEncoder(errors)
        IncrementalEncoder.__init__(self, errors)
    def encode(data, final=False):
        let incoming = self.pending + list(self.utf16encoder.encode(data))
        self.pending = []
        let offset = 0
        let out = ByteCatenator()
        let chunksize = 6 if self.mode == "base64" else 2
        while offset < len(incoming):
            let chunk = incoming[offset:offset + chunksize]
            if len(chunk) < chunksize and not final:
                self.pending = chunk
                return out.getvalue()
            if self.mode == "ascii":
                if chunk[0] or (chunk[1] not in _verbatim_utf7):
                    out.add(b"+")
                    self.mode = "base64"
                    chunksize = 6
                    continue
                out.add(bytes([chunk[1]]))
            else:
                if (not chunk[0]) and (chunk[1] in _verbatim_utf7):
                    if chunk[1] not in _utf7_not_need_hyphen:
                        out.add(b"-")
                    self.mode = "ascii"
                    chunksize = 2
                    continue
                else if len(chunk) >= 4 and (not chunk[2]) and (chunk[3] in _verbatim_utf7):
                    chunk = chunk[:2]
                else if len(chunk) == 6 and (not chunk[4]) and (chunk[5] in _verbatim_utf7):
                    chunk = chunk[:4]
                out.add(encode_base64(chunk).rstrip("=").encode())
            offset += len(chunk)
        if final and self.mode == "base64":
            self.mode = "ascii"
        return out.getvalue()
    def reset():
        self.utf16encoder.reset()
        self.mode = "ascii"
    def getstate():
        return (self.utf16encoder.getstate(), self.mode, self.pending)
    def setstate(state):
        self.utf16encoder.setstate(state[0])
        self.mode = state[1]
        self.pending = state[2]

register_kuroko_codec(["utf-7", "utf7", "u7", "unicode-1-1-utf-7"],
    Utf7IncrementalEncoder, None)


class EucJpFullIncrementalEncoder(AsciiIncrementalEncoder):
    name = "euc-jp-full"
    html5name = None
    encoding_map = encode_euc90

register_kuroko_codec(["euc-jp-full"],
    EucJpFullIncrementalEncoder, XEucJpIncrementalDecoder)


class EucJis2004IncrementalEncoder(AsciiIncrementalEncoder):
    name = "euc-jis-2004"
    html5name = None
    encoding_map = encode_euc04

class EucJis2004IncrementalDecoder(AsciiIncrementalDecoder):
    name = "euc-jis-2004"
    html5name = None
    decoding_map = decode_euc04
    dbrange = tupleOf(0x8E, *range(0xA1, 0xFE + 1))
    tbrange = (0x8F,)
    trailrange = tupleOf(*range(0xA1, 0xFE + 1))

register_kuroko_codec(["euc-jis-2004", "jisx0213", "eucjis2004", "euc_jis2004", 
        "euc_jisx0213", "eucjisx0213"],
    EucJis2004IncrementalEncoder, EucJis2004IncrementalDecoder)


class ShiftJis2004IncrementalEncoder(AsciiIncrementalEncoder):
    name = "shift-jis-2004"
    html5name = None
    encoding_map = encode_sjis04
    ascii_exceptions = (0x5C, 0x7E)

class ShiftJis2004IncrementalDecoder(AsciiIncrementalDecoder):
    name = "shift-jis-2004"
    html5name = None
    decoding_map = decode_sjis04
    ascii_exceptions = (0x5C, 0x7E)
    dbrange = (129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 
               146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 224, 225, 226, 
               227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 
               244, 245, 246, 247, 248, 249, 250, 251, 252)
    trailrange = tupleOf(*range(64, 126 + 1), *range(128, 252 + 1))

register_kuroko_codec(["shift_jis-2004", "shiftjis2004", "sjis_2004", "s_jis_2004", 
        "shift_jisx0213", "shiftjisx0213", "sjisx0213", "s_jisx0213"],
    ShiftJis2004IncrementalEncoder, ShiftJis2004IncrementalDecoder)


class AsciiJohabIncrementalEncoder(AsciiIncrementalEncoder):
    name = "johab-ascii"
    html5name = None
    encoding_map = encode_johab_ascii

class AsciiJohabIncrementalDecoder(AsciiIncrementalDecoder):
    name = "johab-ascii"
    html5name = None
    decoding_map = decode_johab_ascii
    dbrange = tupleOf(*range(0x84, 0xF9 + 1))
    # Trail ranges for hangul and nonhangul are different, but this is their union.
    trailrange = tupleOf(*range(0x31, 0x7E + 1), *range(0x81, 0xFE + 1))

register_kuroko_codec(["cp1361", "ms1361", "johab", "x-johab", "johab-ascii"],
    AsciiJohabIncrementalEncoder, AsciiJohabIncrementalDecoder)


class EbcdicJohabIncrementalEncoder(BaseEbcdicIncrementalEncoder):
    name = "johab-ebcdic"
    html5name = None
    sbcs_encode = encode_nbyte_ebcdic
    dbcshost_encode = encode_johab_ebcdic

class EbcdicJohabIncrementalDecoder(BaseEbcdicIncrementalDecoder):
    name = "johab-ebcdic"
    html5name = None
    sbcs_decode = decode_nbyte_ebcdic
    dbcshost_decode = decode_johab_ebcdic

register_kuroko_codec(["cp933", "ibm-933", "933", "x-IBM933", "ibm-1364", "x-IBM1364",
        "johab-ebcdic"],
    EbcdicJohabIncrementalEncoder, EbcdicJohabIncrementalDecoder)


class JisEncodingIncrementalEncoder(Iso2022JpIncrementalEncoder):
    name = "jis_encoding"
    html5name = None
    encodes_sbcs = [None, None, encode_jis7katakana]
    encodes_dbcs = [None, None, None, encode_jis7, encode_jis78, encode_jis90p2,
                    encode_jis00, encode_jis00p2, encode_jis04, encode_gb7, encode_ksc7]
    encode_supershift_latin = encode_lat1supp
    encode_supershift_greek = encode_greksupp
    super_shift = True
    escs_onebyte = {0: 0x42, 1: 0x4A, 2: 0x49}
    escs_twobyte = {3: 0x42, 4: 0x40, 5: 0x44, 6: 0x4F, 7: 0x50, 8: 0x51, 9: 0x41, 10: 0x43}
    attitude = "eager"

class JisEncodingIncrementalDecoder(Iso2022JpIncrementalDecoder):
    name = "jis_encoding"
    html5name = None
    decodes_sbcs = [None, None, decode_jis7katakana]
    decodes_dbcs = [None, None, None, decode_jis7, decode_jis78, decode_jis90p2,
                    decode_jis00, decode_jis00p2, decode_jis04, decode_gb7, decode_ksc7]
    decode_shiftout = decode_jis7katakana
    decode_supershift_latin = decode_lat1supp
    decode_supershift_greek = decode_greksupp
    # 0x48 is not ASCII or JIS-Roman, but SEN 85 02 00 Annex C. It is however misused for either
    #   ASCII or JIS-Roman in some encoders, so it is a "good idea for software to recognise,
    #   but not to generate" (—Lunde) it for JIS-Roman when decoding JIS_encoding.
    escs_onebyte = {0x42: 0, 0x48: 1, 0x49: 2, 0x4A: 1}
    escs_twobyte = {0x40: 4, 0x41: 9, 0x42: 3, 0x43: 10, 0x44: 5, 0x4F: 6, 0x50: 7, 0x51: 8}
    two_byte_modes = [3, 4, 5, 6, 7, 8, 9, 10]
    new_twobytes = True
    shift_out = True
    super_shift = True
    concat_lenient = True

register_kuroko_codec(["jis_encoding", "csjisencoding", "jis", "jis7"],
    JisEncodingIncrementalEncoder, JisEncodingIncrementalDecoder)


class Iso2022Jp1IncrementalEncoder(Iso2022JpIncrementalEncoder):
    name = "iso-2022-jp-1"
    html5name = None
    encodes_sbcs = [None, None]
    encodes_dbcs = [None, None, encode_jis90p2, encode_jis7]
    escs_onebyte = {0: 0x42, 1: 0x4A}
    escs_twobyte = {3: 0x42, 2: 0x44}
    attitude = "eager"

register_kuroko_codec(["iso-2022-jp-1", "iso2022-jp-1", "iso2022jp-1"],
    Iso2022Jp1IncrementalEncoder, JisEncodingIncrementalDecoder)


class Iso2022JpExtIncrementalEncoder(Iso2022JpIncrementalEncoder):
    name = "iso-2022-jp-ext"
    html5name = None
    encodes_sbcs = [None, None, encode_jis7katakana]
    encodes_dbcs = [None, None, None, encode_jis90p2, encode_jis7]
    escs_onebyte = {0: 0x42, 1: 0x4A, 2: 0x49}
    escs_twobyte = {4: 0x42, 3: 0x44}
    attitude = "eager"

register_kuroko_codec(["iso-2022-jp-ext", "iso2022-jp-ext", "iso2022jp-ext"],
    Iso2022JpExtIncrementalEncoder, JisEncodingIncrementalDecoder)


class Iso2022Jp2IncrementalEncoder(Iso2022JpIncrementalEncoder):
    name = "iso-2022-jp-2"
    html5name = None
    encodes_sbcs = [None, None]
    encodes_dbcs = [None, None, encode_jis90p2, encode_jis7, encode_gb7, encode_ksc7]
    encode_supershift_latin = encode_lat1supp
    encode_supershift_greek = encode_greksupp
    super_shift = True
    escs_onebyte = {0: 0x42, 1: 0x4A}
    escs_twobyte = {3: 0x42, 2: 0x44, 4: 0x41, 5: 0x43}
    attitude = "eager"

register_kuroko_codec(["iso-2022-jp-2", "iso2022-jp-2", "iso2022jp-2", "csISO2022JP2"],
    Iso2022Jp2IncrementalEncoder, JisEncodingIncrementalDecoder)


# Bit confusing to explain what this bit is doing, so let me explain:
#     The JIS X 0213 variants of ISO-2022-JP should encode to JIS X 0213 before encoding to any
#   extension to JIS X 0208 (assuming they "should" encode to extensions at all). So we remove any
#   characters that are encoded to different locations in JIS X 0213.
#     Since NEC Row 13 is retained it JIS X 0213, but should be encoded in the JIS X 0213 state not
#   the JIS X 0208 state, it is excluded manually (lead byte 0x2D).
#     As an additional effect, this also removes certain Unicode characters that are mapped
#   differently by Microsoft/WHATWG versus by JIS X 0213, e.g. Microsoft two-way maps the Unicode
#   fullwidth tilde to the JIS wave dash, while JIS X 0213 includes a separate tilde character
#   mapped to both the fullwidth tilde and (where appropriate) the ASCII tilde, and maps the JIS
#   wave dash to the Unicode wave dash. This forces those characters to be encoded to JIS X 0213.
let encode_jis7_reduced = {}
for i in encode_jis7.keys():
    if (i not in encode_jis00 or encode_jis00[i] == encode_jis7[i]) and (i not in encode_jis00p2):
        if encode_jis7[i][0] != 0x2D:
            encode_jis7_reduced[i] = encode_jis7[i]


class Iso2022Jp3IncrementalEncoder(Iso2022JpIncrementalEncoder):
    name = "iso-2022-jp-3"
    html5name = None
    encodes_sbcs = [None, None, encode_jis7katakana]
    encodes_dbcs = [None, None, None, encode_jis7_reduced, encode_jis00, encode_jis00p2]
    escs_onebyte = {0: 0x42, 1: 0x4A, 2: 0x49}
    escs_twobyte = {3: 0x42, 4: 0x4F, 5: 0x50}
    attitude = "eager"

register_kuroko_codec(["iso-2022-jp-3", "iso2022-jp-3", "iso2022jp-3"],
    Iso2022Jp3IncrementalEncoder, JisEncodingIncrementalDecoder)


class Iso2022Jp2004IncrementalEncoder(Iso2022JpIncrementalEncoder):
    name = "iso-2022-jp-2004"
    html5name = None
    encodes_sbcs = [None, None, encode_jis7katakana]
    encodes_dbcs = [None, None, None, encode_jis7_reduced, encode_jis00p2, encode_jis04]
    escs_onebyte = {0: 0x42, 1: 0x4A, 2: 0x49}
    escs_twobyte = {3: 0x42, 4: 0x50, 5: 0x51}
    attitude = "eager"

register_kuroko_codec(["iso-2022-jp-2004", "iso2022-jp-2004", "iso2022jp-2004"],
    Iso2022Jp2004IncrementalEncoder, JisEncodingIncrementalDecoder)


class Utf32IncrementalEncoder(IncrementalEncoder):
    name = "utf-32"
    html5name = None
    encoding_map = {}
    endian = "little"
    include_bom = True
    # -1: BOM not yet emitted if applicable
    #  0: BOM emitted
    state = None
    def push_word(word, out):
        if self.endian == "little":
            out.add(bytes([word & 0xFF, (word >> 8) & 0xFF, (word >> 16) & 0xFF, (word >> 24) & 0xFF]))
        else if self.endian == "big":
            out.add(bytes([(word >> 24) & 0xFF, (word >> 16) & 0xFF, (word >> 8) & 0xFF, word & 0xFF]))
        else:
            raise ValueError("unexpected endian value: " + repr(self.endian))
    def encode(string, final = False):
        let out = ByteCatenator()
        let offset = 0
        if self.include_bom and self.state == -1:
            self.push_word(0xFEFF, out)
        self.state = 0
        while 1: # offset can be arbitrarily changed by the error handler, so not a for
            if offset >= len(string):
                return out.getvalue()
            let i = string[offset]
            if not (0xD800 <= ord(i) and ord(i) < 0xE000):
                self.push_word(ord(i), out)
                offset += 1
            else: # i.e. trying to encode a surrogate "codepoint"
                let error = UnicodeEncodeError(self.name, string, offset, offset + 1,
                            "surrogate codepoint")
                let errorret = lookup_error(self.errors)(error)
                for i in errorret[0]:
                    self.push_word(i, out)
                offset = errorret[1]
                if offset < 0:
                    offset += len(string)
    def reset():
        self.state = -1
    def getstate():
        return self.state
    def setstate(state):
        self.state = state

class Utf32IncrementalDecoder(IncrementalDecoder):
    name = "utf-32"
    html5name = None
    force_endian = None # subclass may set to "little" or "big"
    # -1: expecting BOM
    #  0: LE
    #  1: BE
    state = None
    pending = b""
    def decode(data_in, final = False):
        let data = self.pending + data_in
        self.pending = b""
        let out = StringCatenator()
        let offset = 0
        let leader = []
        while 1: # offset can be arbitrarily changed by the error handler, so not a for
            if (offset + 3) >= len(data):
                let leader_bytes = []
                for i in leader:
                    if self.state == 1:
                        leader_bytes.append((i >> 8) & 0xFF)
                        leader_bytes.append(i & 0xFF)
                    else:
                        leader_bytes.append(i & 0xFF)
                        leader_bytes.append((i >> 8) & 0xFF)
                if offset < len(data): # i.e. one to three isolated bytes at the end
                    leader_bytes.extend(list(data)[offset:])
                return self._handle_truncation(out, None, final, data, offset, leader_bytes)
            let i
            if self.state != 1:
                i = data[offset] | (data[offset + 1] << 8) | (data[offset + 2] << 16) | (data[offset + 3] << 24)
            else:
                i = data[offset + 3] | (data[offset + 2] << 8) | (data[offset + 1] << 16) | (data[offset] << 24)
            if self.state == -1:
                if self.force_endian == "little":
                    self.state = 0 # keep BOM if endian specified, per Python.
                    i = data[offset] | (data[offset + 1] << 8) | (data[offset + 2] << 16) | (data[offset + 3] << 24)
                else if self.force_endian == "big":
                    self.state = 1
                    i = data[offset + 3] | (data[offset + 2] << 8) | (data[offset + 1] << 16) | (data[offset] << 24)
                else if i == 0xFEFF:
                    self.state = 0
                    i = None
                else if i == 0xFFFE0000:
                    self.state = 1
                    i = None
                else if i & 0xFF000000:
                    # UTF-32's highest byte will never be used, so if it has a value it's obviously
                    #   the other endian.
                    self.state = 1
                    i = data[offset + 3] | (data[offset + 2] << 8) | (data[offset + 1] << 16) | (data[offset] << 24)
                else:
                    # Default to LE, to be consistent with our (WHATWG-influenced) UTF-16 handling.
                    # Note that except in the relatively unlikely event of the stream starting with
                    #   the first character in a plane, the previous clause would have detected
                    #   UTF-32BE already though.
                    self.state = 0
            if i == None:
                offset += 4
            else if not (0xD800 <= i and i < 0xE000) and (i < 0x110000):
                out.add(chr(i))
                offset += 4
            else:
                let errorstart = offset - (len(leader) * 2)
                let errorend = errorstart + 4
                let reason
                if i > 0x110000:
                    reason = "UTF-32 code beyond Unicode"
                else:
                    reason = "surrogate word in UTF-32"
                let error = UnicodeDecodeError(self.name, data, errorstart, errorend, reason)
                leader = []
                let errorret = lookup_error(self.errors)(error)
                out.add(errorret[0])
                offset = errorret[1]
                if offset < 0:
                    offset += len(string)
    def reset():
        self.pending = b""
        self.state = -1
    def getstate():
        return (self.pending, self.state)
    def setstate(state):
        self.pending = state[0]
        self.state = state[1]

class Utf32BeIncrementalEncoder(Utf32IncrementalEncoder):
    name = "utf-32be"
    html5name = None
    endian = "big"
    include_bom = False

class Utf32BeIncrementalDecoder(Utf32IncrementalDecoder):
    name = "utf-32be"
    html5name = None
    force_endian = "big"

class Utf32LeIncrementalEncoder(Utf32IncrementalEncoder):
    name = "utf-32le"
    html5name = None
    endian = "little"
    include_bom = False

class Utf32LeIncrementalDecoder(Utf32IncrementalDecoder):
    name = "utf-32le"
    html5name = None
    force_endian = "little"

register_kuroko_codec(["utf-32", "utf32", "iso-10646-ucs-4", "ucs-4", "u32"],
    Utf32IncrementalEncoder, Utf32IncrementalDecoder)
register_kuroko_codec(["utf-32le", "utf-32-le"],
    Utf32LeIncrementalEncoder, Utf32LeIncrementalDecoder)
register_kuroko_codec(["utf-32be", "utf-32-be"],
    Utf32BeIncrementalEncoder, Utf32BeIncrementalDecoder)











